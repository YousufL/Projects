# -*- coding: utf-8 -*-
"""Salary Cap Projections.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JkOXW0ni87O-ApyF3nNRmtj23SaZKYP-

# Introduction

The University of Toronto Hockey Analytics Club (UTHAC) were consulted by the Columbus Blue Jackets to develop a statistical model to project NHL skater contracts for the 2019-2020 season. The model is based off of research conducted in the public sphere, espcially that of Matt Cane and Evolving Wild. We will go into detail as to where our model differs and where there is opportunity to conduct additional research and fine tune the model to Columbus's standards.

The final model projections are produced by two individual models - one model to predict term and the other to predict contract cap hit%. A players term has a large influence on their resultant cap hit% and is one of the most important inputs into the cap %  model. We will present our findings and results from the term model first followed by our findings for the cap % model.

# Research and Influence from Other Models

Fortunately, a lot of the research required to develop models for skater contracts is publically published and available. Our model follows the following assumptions and research conducted by Matt Cane and Evolving Wild.


**Matt Cane**

*   Excluded (most) league minimum contracts and contracts valued less than $1 million AAV

This helped us deal with the class imbalance that exists in player contract length. Most contracts are 1-2 years long and the majority of contracts signed are less than $1 million. Projecting these players has little value and decreases the models ability to project longer term deals (4,5,6,7 and 8 years).

**Evolving Wild**

*   Weighing of previous season statistics that are fed into the model. A players contract year, contract year -1 and contract year -2 have an influence on a players contract and are weighted accordingly.

Prior Years | Term Weights | Cap % Weights 
--- | --- | ---
n-1 | 69.23% | 50.00%
n-2 | 19.23% | 26.32%
n-3 | 11.54% | 23.68%

*   Age has to be treated as a categorical variable, with specific age groups contributing to an age tier. If a players age falls into the range of an age tier they are placed in said tier.


Term Model | AAV Model
--- | ---
Tier 1 | <=22
Tier 2| 23 & 24
Tier 3 | 25 & 26
Tier 4 | 27-29
Tier 5 | 30-34
Tier 6 | >=35

* Input variables (Term Model)

Features (categorical):
Position, age tier, contract status, draft round (1,2), max_possible

Features (continuous): TOI, TOI%, G, A1, iCF, ixG, giveaways, takeaways, 5v5 on ice GF diff, 5v5 on ice CF diff

* Input Variables (AAV Model)

Features (categorical):
Term, position, age tier, contract status, draft round (1-2)

Features (continuous):
TOI, TOI%, G, A1, iCF, iBLK, giveaways, takeaways, iPEND2, iPENT2, 5v5 on-ice GF diff

# The SHAP Library

Throughout the report we will reference 'SHAP values', 'SHAP model outputs' and 'SHAP plots'. SHAP stands for 'SHapley Additive exPlanations' and it is a python library designed to model the behaviour of a variety of statistical algorithms.

It provides insights on variable importance and provides extremely useful visuals to visualize them. The actual SHAP values are calculated through some high level statistics and mathematics which we will not go into details about because it is out of the scope of what this project is. 

The only thing that needs to be known about SHAP is that positive values mean an increase in model output (higher term and higher cap hit%) and lower/negative values for SHAP indicate a decrease in model output.

# Term Model

The term model aims to predict a player's contract length, and provides a probability for each possible contract length. The contract length that has the highest probability is taken as a players final predictions.

In addition to the variables used by Evolving Wild we also included a players original contract status, arbitration rights, original contract length, isH%, PDO, ZSR, CF% QOT, TOI% QOC, CF% QOC and short-handed TOI%. We initially used TOI% QOT and GS but found they were extremely correlated with TOI% and production metrics respectively so we removed them.

# Uploading and Visualizing Training Dataset
"""

#@title
# Upload Training File
from google.colab import files
uploaded=files.upload()

"""The following table is the first five rows of the training dataset. Our training data contains 1232 contracts signed between 2011 and 2019. As discussed previously, we removed most league minimum contracts and contracts less than $1 million AAV to reduce training time and make the model more robust to longer contracts. 

The  input variables that were used to train the model are as follows,

* **POS** - 1 for forwards, 0 for defencemen
***AGE_1** - Age tier 1, skaters under 22 
***AGE_2**- Age tier 2, skaters 23 and 24 
***AGE_3** - Age tier 3, skaters 25 and 26
***AGE_4** - Age tier 4, skaters 27-29
***AGE_5** - Age tier 5, 30-34
***OCS_RFA** - Skaters orginal contract status was RFA
***OCS_UFA** - Skaters origial contract status was UFA
***NSS** - Skaters new signing status, 1 for UFA, 0 for RFA
***ARBITRATION** - Skater arbitration rights, 1for yes, 0 for no
***DRAFTRD1**- Skater was drafted in the first round
***DRAFTRD2** - skater was drafted in the second round
***MAX_POSSIBLE** - Whether a player was eligible for a max length contract (8 years). This variable was included because the model would give long term deals to older players like Justin Williams or Joe Thornton, so by specifiying that they were not eligble to recieve a max contract helped with these unreasonable projections 
***OCL** - Skaters original contract length
***OCH%** -  Skaters original cap hit%
***TOI** - Skater total TOI (All situations)
***TOI%** - Skater TOI% (All situations)
***G** - Skaters goal total (All situations)
***A1** -  Skater primary assist total (All situations)
***iCF** - Skater individual corsi for (shot attempts for, All situations)
***ixG** - Skater individual expected goals (All situations)
***GIVE** - Skater giveaways (All situations)
***TAKE** - Skater takewaways (All situations)
***5v5_GF_DIFF** - Skater 5v5 on-ice goals for differential
***5v5_CF_DIFF** - Skater 5v5 on-ice corsi for differential
***iSh%** - Skater individual shooting % (All situations)
***PDO** - Skater PDO (All situations)
***ZSR** - Skater zone start ratio (All situations)
***CF%_QOT** - Skater quality of teammates measured by teammate CF%
***TOI%_QOC** - Skater quality of competition measured by competitions TOI%
***CF%_QOC** - Skater quality of competition measured by competitions CF%
***SHTOI%** - Skater short-handed TOI%

The output variable for the multiclassification model is **'New_Contract_Length'**.

# **Training Dataset**
"""

#@title
import numpy as np
import pandas as pd
import datetime
import random

#import io
#data=pd.read_csv(io.BytesIO(uploaded['Multiclassification.csv']))
#data.head()

"""# **Matrix of input variables (X)**"""

#@title
X=data.iloc[:,1:33]
Y=data.iloc[:,33]
X.head()

"""# **Output Variable Y**"""

#@title
Y.head()

"""# **Visualizing distribution of input variables**

The following plots show the distributions of the input variables used in the model. The X-axis for the plots indicates the variables value and the y-axis is the frequency the variable appears at that value.

For example, the first plot 5v5_CF_DIFF shows that most players have a value near 0 (around 400), with outliers existing at +/- 250 with very few players having those values.

The fourth plot, AGE_1, represents a histogram for a categorical variable so there are only two possible values, 0 and 1. The plot indicates that roughly 100 players signed new contracts before they were 22. The next plot AGE_2, shows a similiar distribution with approximately 300 players signing their contracts at the ages of 23 and 24.
"""

#@title
X.hist(figsize=(20,20))

"""# **Visualizing distribution of output variable** 

As stated previously, the majority of contracts signed are 1 or 2 years in length with the remaining term options being minority classes.
"""

#@title
sns.set_style("white")
sns.set_color_codes(palette='deep')
f, ax = plt.subplots(figsize=(8, 7))
sns.distplot(data['New_Contract_Length'], color="b");
ax.xaxis.grid(False)
ax.set(ylabel="Frequency")
ax.set(xlabel="New Contract Length")
ax.set(title="New Contract Length Distribution")
sns.despine(trim=True, left=True)
plt.show()

"""# **Visualizing the relationship of input varibles to output variables**

The following plots show the relationship of every input variable to New Contract Length. Because the output variable is categorical (unlike cap hit% which is continous) it is difficult to pin-point what exactly contributes to contract length. 

The plots generally show a higher density of longer term contracts for players with high counting stats. This is most evident for TOI%, G, PDO, ZSR and CF% QOT. 

So essentially players that play most of their team's minutes with other good players and score goals are most likely to get longer term contracts. 

 High PDO and ZSR could indicate players with legitimate shooting talent that are put in favourable situations to score and are frequenlty relied upon by their team.  These players are more likely to be locked down long term.
"""

#@title
# Finding numeric features
numeric_dtypes = ['int64','float64']
numeric = []
for i in data.columns:
    if data[i].dtype in numeric_dtypes:
        if i in ['TotalSF', 'Total_Bathrooms','Total_porch_sf','haspool','hasgarage','hasbsmt','hasfireplace']:
            pass
        else:
            numeric.append(i)     
# visualising some more outliers in the data values
fig, axs = plt.subplots(ncols=2, nrows=0, figsize=(9, 68))
plt.subplots_adjust(right=2)
plt.subplots_adjust(top=2)
sns.color_palette("husl", 8)
for i, feature in enumerate(list(data[numeric]), 1):
    if(feature=='MiscVal'):
        break
    plt.subplot(len(list(numeric)), 2, i)
    sns.scatterplot(x=feature, y='New_Contract_Length', hue='New_Contract_Length', palette='Blues', data=data)
        
    plt.xlabel('{}'.format(feature), size=15,labelpad=12.5)
    plt.ylabel('Term', size=15, labelpad=12.5)
    
    for j in range(2):
        plt.tick_params(axis='x', labelsize=12)
        plt.tick_params(axis='y', labelsize=12)
    
    plt.legend(loc='best', prop={'size': 8})
        
plt.show()

"""# **Visualizing the correlation the input variables have with eachother**

The following plot is a correlation matrix of all the input variables. Every input variable is listed on the x and y axis, so that the correlation of every variable can be shown with every other variable. The dark blue diagonal line shows the correlation of every variable to itself, hence the dark blue diagonal line through the middle of the plot.  The darker the blue box, the more correlated the input variables. For example if we find 'G' on the y-axis we can move across the plot from left to right to see where darker blue boxes appear to see what other variables correlate with goals. POS, A1, iCF, ixG, takeaways, ish%, and CF% QOT all seem to have some correlation with goals. 

Some other highly correlated variables are Arbitration with AGE_2, AGE_3 and OCS_RFA. This makes intuitive sense as players with arbitration rights are usually between 22-26 and have had at least 1 RFA deal as a past contract.
"""

#@title
corr = X.corr()
plt.subplots(figsize=(15,12))
sns.heatmap(corr, vmax=0.9, cmap="Blues", square=True)

"""# **Model Training**

We tested several algorithms and most worked well for our problem. We opted to use Catboost as our algorithm because it provided the highest micro F1 accuracy score.

A model's F1 score is it's weighted average of it's precision and recall. 

"**Recall** is the number of True Positives divided by the number of True Positives and the number of False Negatives. Put another way it is the number of positive predictions divided by the number of positive class values in the test data." [https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/]

"**Precision** is the number of True Positives divided by the number of True Positives and False Positives. Put another way, it is the number of positive predictions divided by the total number of positive class values predicted."[https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/]

Recall = (True Positives/(True Positives + False Negatives))

Precision = (True Positives/(True Positives + False Positives))

F1 = 2*((precision*recall)/(precision+recall))

Our chosen metric, Micro F1, puts more emphasis on a model's accuracy in predicting the minority classes. We felt this to be more important than overall accuracy because it makes the model more robust to predicting contracts of exceptional players who get longer term deals.

# Setting up the Catboost Classifier
"""

#@title
# Install catboost
!pip install catboost

#@title
#Import Libraries
import catboost
from catboost import CatBoostClassifier

#Define Catboost Model
modelCB = CatBoostClassifier(loss_function='MultiClass', learning_rate=0.01, depth=10, iterations=1000,border_count=32,task_type='GPU')

modelCB

"""We trained the model and evaluated it against the training set. We used k-fold cross validation with 5 folds to evaluate the model. 

In k-fold cross validation, the model splits the data into groups (in our case 5) with 4 groups used as training and 1 group used as testing. This is done five times so each group is represented as the testing set at least once. The average of these scores is the model score.
"""

#@title
#Import library for k-fold cross validation
from sklearn.model_selection import cross_val_score

#Running cross validation
scores = cross_val_score(modelCB, X, Y, cv=5, scoring='f1_micro')

#@title
#Averaging the scores
scores.mean()

"""The model achieved a  micro F1 score of 0.4666. 

For reference a score of 1 would have been perfect. We have no score to compare this to, but we believe predicting nearly 50% of contracts when there are 8 possible classes is favourable. We could have done additional model tuning to improve this result but didn't see the point as the regression model provides a cap hit% for every possible term option.

# Fitting the Model to the Testing Set
"""

#@title
# Upload Training File
from google.colab import files
uploaded=files.upload()

"""The following table is the data for our testing set, which contains all players eligible to sign a new skater contract for the 2019-2020 season. AHL veterans and players with few NHL GP were removed."""

#@title
import io
X_test=pd.read_csv(io.BytesIO(uploaded['Classification_Final.csv']))
X_test.head()
z_test=X_test.iloc[:,1:]
player_names=X_test.iloc[:,0]
z_test.head()

#@title
modelCB.fit(X,Y)

#@title
Predicted_Probabilities = pd.DataFrame(modelCB.predict_proba(z_test))
Predicted_Proba = pd.concat([player_names, Predicted_Probabilities], axis=1)

"""# **The predicted probabilities of the 2019 class**

The following table shows the probability a player signs for every possible contract length (column 0 is 1 year and column 7 is 8 years)
"""

#@title
Predicted_Proba

"""# **The predicted length of the 2019 class**

The following table is a players final term length prediction, for example Marner's highest term probability was 8 with 21.4% hence it was his final model prediciton. 

Most of these projections seem reasonable, however Gardiner, Eberle and Hayes at 8 years and konecny at 7 are probably too long.
"""

#@title
Predicted_Lengt = pd.DataFrame(modelCB.predict(z_test))
Predicted_Length = pd.concat([player_names, Predicted_Lengt], axis=1)
Predicted_Length

"""# Visualizing Feature Importance

Judging feature importance in a multiclass classification problem is challenging. Each variable contributes to an increase or decrease in probability for every class. The model will struggle to find consistency and identify trends as players with similiar stats end up signing a variety of different contracts with different lengths depending on many external factors.

The model doesn't neccesarily consider the inputs as driving factors for a prediction but rather uses the inputs to find similiar players and what their resultant contract length was.
"""

#@title
# Install SHAP
!pip install shap==0.27
import shap

#@title
#Vizuallise feature importances with Shap (global)
explainer = shap.TreeExplainer(modelCB)
shap_values = explainer.shap_values(X)

"""The following graph shows the 20 most important features in the model, and their impact on every class. The graph is dominated by dark blue because class 1 represents 2 year contracts which made up most of our data set. 

These results are quite interesting and we'll go through the 10 most important features and why we feel the model considered them so heavily, 



**1. OCH%**

A players original cap hit% is a good indicator of their future contract length. Most players second contract after their ELC is a contract that is close in cap hit% to their original ELC contract. Most fringe NHL players sign a contract in the neigborhood of 2 years X  $650,000-$1,000,000, so class 1 contracts (2 years) are dominated by this varaible. 

For players like Matthews's who's cap hit% jumps from 1% to over 15% on their second contract, this variable has little value, and by the graph has little influence on longer term deals. This makes sense as longer term deals after ELC's are usually high in cap%. 

Matthew's third contract, however, will probably be influenced by his current deal. His current cap hit% of 15 will be a good indicator of another long term high AAV deal as a UFA. 

**2. TOI%**

Players who play a lot of minutes for their team consistently are usually subject to longer term contracts. 

**3. OCL**

Similiar to OCH%, original contract length is a good indicator of future contract length. Players like Matthews who recieve a 5 year RFA deal will probably sign a 5-8 year deal as a UFA. Players who consistenly recieve 1-2 year contracts are more fringe players who teams do not commit term to. 


**4. DRAFTRD1**

First round players are usually exceptional talents who recieve more long term deals than players drafted later in the draft or come to the NHL as free agent

**5. CF%_QOC**

A player's quality of competiton is a good indicator of their place in the lineup. If a player has a high QOC they consistently play against other teams top lines - which is a good indicator that they are high up on their own teams depth charts. Third and fourth line players recieve shorter deals while first and second liners recieve 5,6,7 and 8 year contracts. 

**6. iCF**

Suprisingly iCF is the first counting stat the model found important. This is probably because iCF is correlated with high TOI% and other box stats like goals and primary assists. Nonetheless players with more indivdual shot attempts usually recieve longer term contracts then those with few. 

**7. 5v5_CF_DIFF**

5v5_CF_DIFF indicates whether a player controls the shot clock when on the ice at 5v5. More shot attempts for (usually) leads to more goals for and more individual impact on the outcome of the game. Players who control play recieve longer term deal to those that do not. 


**8. Giveaways**

Giving the puck away is not a desireable metric, however it is correlated with other important metrics like TOI and TOI% so the model found it to be important in determining contract length for this reason.


**9. TOI**

Similiar to TOI%, however a higher raw TOI value indicates a healthier player who plays in more games. 

**10. OCS_RFA**

If a players original contract status was RFA, it is a good indicator they will recieve a 2 year deal. This is because most players recieve a cheap 2 year contract after their ELC deal. 

For exceptional players coming off their RFA (ELC) deals, they are almost guranteed to recieve a 5,6,7 or 8 year deal if they do not opt for a bridge contract.
"""

#@title
shap.summary_plot(shap_values, X)

"""The following table captures the overall feature importance for each variable across all classes. The shap_importance indicates what is driving the model above the average model ouput, so in our case what is driving the model away from 1-2 year deals towards 5-8 year deals? 

The top 10 variable are similiar to what was found in the previous section with only A1 and MAX_POSSIBLE being added to the list. MAX_POSSIBLE is a binary variable which prevents the model from giving longer term deals to older players (over the age of 35). The model found it to be important for predicting longer term contracts as players in all other age tiers are more likely to recieve a long term deal. 

A1 is pretty self explanatory - players with more primary points and assists recieve longer contracts.
"""

#@title
shap_sum = np.abs(shap_values[3]).mean(axis=0)
importance_df = pd.DataFrame([X.columns.tolist(), shap_sum.tolist()]).T
importance_df.columns = ['column_name', 'shap_importance']
importance_df = importance_df.sort_values('shap_importance', ascending=False)
importance_df

"""# Conclusion - Term Model

The term model performed admirably for this years skater class and provides some additional insight as to what contributes to a skater's contract length. 

Player length can be influenced by many intangibles that can't be captured in a statistical model. A player's relationship with their general manager, coach and teammates could all have an effect on how long they choose to commit to a team. Player's and agents could be looking to maximize career earnings so player's could opt to sign shorter deals that take up fewer UFA years and give them more opportunity to sign new contracts as the cap ceiling increases.

# Player Cap Percentage Model

The cap percentage model predicts a players cap hit for every possible term option.

#  Uploading and Visualizing Training Dataset
"""

#@title
# Upload Training File
from google.colab import files
uploaded=files.upload()

"""The following table is the first five rows of the training dataset. The training dataset for the cap hit% model is almost identical to that of the term model except for a few different input variables. 

The  input variables that were used to train the model are as follows,

* **POS** - 1 for forwards, 0 for defencemen
***AGE_1** - Age tier 1, skaters under 22 
***AGE_2**- Age tier 2, skaters 23 and 24 
***AGE_3** - Age tier 3, skaters 25 and 26
***AGE_4** - Age tier 4, skaters 27-29
***AGE_5** - Age tier 5, 30-34
***OCS_RFA** - Skaters orginal contract status was RFA
***OCS_UFA** - Skaters origial contract status was UFA
***NSS** - Skaters new signing status, 1 for UFA, 0 for RFA
***ARBITRATION** - Skater arbitration rights, 1for yes, 0 for no
***NCL1** - 1 year contract
***NCL2** - 2 year contract
***NCL3** - 3 year contract
***NCL4** - 4 year contract
***NCL5** - 5 year contract
***NCL6** - 6 year contract
***NCL7** - 7 year contract
***DRAFTRD1**- Skater was drafted in the first round
***DRAFTRD2** - skater was drafted in the second round
***OCL** - Skaters original contract length
***OCH%** -  Skaters original cap hit%
***TOI** - Skater total TOI (All situations)
***TOI%** - Skater TOI% (All situations)
***G** - Skaters goal total (All situations)
***A1** -  Skater primary assist total (All situations)
***iCF** - Skater individual corsi for (shot attempts for, All situations)
***GIVE** - Skater giveaways (All situations)
***TAKE** - Skater takewaways (All situations)
***5v5_GF_DIFF** - Skater 5v5 on-ice goals for differential
***iBLK** - Individual blocked shots (All situations)
***iPENT2** - Individual minor penalties taken (All situations)
***iPEND2** - Individual minor penalties drawn (All situations)
***iSh%** - Skater individual shooting % (All situations)
***PDO** - Skater PDO (All situations)
***ZSR** - Skater zone start ratio (All situations)
***CF%_QOT** - Skater quality of teammates measured by teammate CF%
***TOI%_QOC** - Skater quality of competition measured by competitions TOI%
***CF%_QOC** - Skater quality of competition measured by competitions CF%
***SHTOI%** - Skater short-handed TOI%

The output variable for the regression model is **NCH%**.

# **Training Dataset**
"""

#@title
import io
import pandas as pd
from google.colab import files
data2=pd.read_csv(io.BytesIO(uploaded['Trade_Market_Training_Final.csv']))
data2.head()

"""# **Matrix of input variables (X)**"""

#@title

X2=data2.iloc[:,1:84]
Y2=data2.iloc[:,84]
X2.head()
#Y2.head()
#cont=X.iloc[:,20:40]
#cont.head()

"""# **Output variable (Y)**"""

#@title
Y2.head()

"""# **Visualizing distribution of input variables**"""

#@title
X2.hist(figsize=(20,20))

"""# **Visualizing distribution of output variable**

Most contracts, and most NHL players are role players who sign 1-2 year deals at a low cap hit%. This is evident in the following distribution as the number of contracts signed with more than 10% cap hit are miniscule in comparison to contracts signed between 0 and 5%.
"""

#@title
sns.set_style("white")
sns.set_color_codes(palette='deep')
f, ax = plt.subplots(figsize=(8, 7))
sns.distplot(data2['NCH%'], color="b");
ax.xaxis.grid(False)
ax.set(ylabel="Frequency")
ax.set(xlabel="NCH%")
ax.set(title="NCH% Distribution")
sns.despine(trim=True, left=True)
plt.show()

"""# **Visualizing the relationship of input varibles to output variables**

Judging by the scatter plots, the variables with the strongest relationship to cap hit % are DRAFTRD1, Age Tier 2, OCH%, TOI, TOI%, G, A1, iCF, giveaways, takeaways, ZSR, CF%_QOC and CF%_QOT. 

Most of the categorical variables, SHTOI%, 5v5_GF_DIFF, iBLK, iPEND2, and IPENT2 are random and have little individual correlation with cap hit%.
"""

#@title
# Finding numeric features
numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
numeric = []
for i in data2.columns:
    if data2[i].dtype in numeric_dtypes:
        if i in ['TotalSF', 'Total_Bathrooms','Total_porch_sf','haspool','hasgarage','hasbsmt','hasfireplace']:
            pass
        else:
            numeric.append(i)     
# visualising some more outliers in the data values
fig, axs = plt.subplots(ncols=2, nrows=0, figsize=(10, 85))
plt.subplots_adjust(right=2)
plt.subplots_adjust(top=2)
sns.color_palette("husl", 8)
for i, feature in enumerate(list(data2[numeric]), 1):
    if(feature=='MiscVal'):
        break
    plt.subplot(len(list(numeric)), 2, i)
    sns.scatterplot(x=feature, y='NCH%', hue='NCH%', palette='Blues', data=data2)
        
    plt.xlabel('{}'.format(feature), size=15,labelpad=12.5)
    plt.ylabel('Cap Hit %', size=15, labelpad=12.5)
    
    for j in range(2):
        plt.tick_params(axis='x', labelsize=12)
        plt.tick_params(axis='y', labelsize=12)
    
    plt.legend(loc='best', prop={'size': 10})
        
plt.show()

"""# **Visualizing the correlation the input variables have with eachother**

Most of the input variables and the variable correlations are the same in the cap hit% model as the term model. 
 
Some strong correlations include,

1. Defense and iBLK
2. Age tiers 2 and 3 with ARBITRATION
3. Age tiers 4 and 5 with UFA as the skaters signing status (NSS)
4. Goals, A1 and iCF with CF%_QOT (the better your teammates the better your counting stats)
"""

#@title
corr = X2.corr()
plt.subplots(figsize=(15,12))
sns.heatmap(corr, vmax=0.9, cmap="Blues", square=True)

"""# Model Training

Our targer error metric for this model is Mean Absolute Error (MAE). MAE measures the average magnitude of errors in a set of predictions without considering the direction of the error (whether a prediction was to high or to low). MAE averages the  absolute differences between predicted and actual values where all individual differences have equal weight.

We chose MAE because we wanted to treat model predictions that we're high or low the same and didn't want to add additional weight to errors made on outliers. 

Although several models acheived low MAE's many of the models predicted unreasonably low cap hit %'s for longer term deals on high-end players. 

We decided on using a blended model, which averages the model scores from several different machine learning algorithms to provide a predicted cap hit %. This not only reduced the overall MAE of the model, but also helped it make more reasonable projections on long term deals.
"""

#@title
#Setting up the Models

# Essentials
import numpy as np
import pandas as pd
import datetime
import random

# Plots
import seaborn as sns
import matplotlib.pyplot as plt

# Models
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor
from sklearn.kernel_ridge import KernelRidge
from sklearn.linear_model import Ridge, RidgeCV
from sklearn.linear_model import ElasticNet, ElasticNetCV
from sklearn.svm import SVR
from mlxtend.regressor import StackingCVRegressor
import lightgbm as lgb
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor

# Stats
from scipy.stats import skew, norm
from scipy.special import boxcox1p
from scipy.stats import boxcox_normmax

# Misc
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import KFold, cross_val_score
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import scale
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import RobustScaler
from sklearn.decomposition import PCA

pd.set_option('display.max_columns', None)

# Ignore useless warnings
import warnings
warnings.filterwarnings(action="ignore")
pd.options.display.max_seq_items = 8000
pd.options.display.max_rows = 8000

import os



#@title
# Setup cross validation folds
kf = KFold(n_splits=10, random_state=42, shuffle=True)

#@title
from sklearn.metrics import mean_absolute_error

# Define error metrics
def rmsle(y, y_pred):
    return mean_absolute_error(y, y_pred)

def cv_rmse(model, X=X2):
    rmse = np.sqrt(-cross_val_score(model, X2, Y2, scoring="neg_mean_absolute_error", cv=kf))
    return (rmse)

# Light Gradient Boosting Regressor
lightgbm = LGBMRegressor(num_leaves=6,learning_rate=0.01, n_estimators=3000, max_bin=200, bagging_fraction=0.8, bagging_freq=4,  bagging_seed=8, feature_fraction=0.2,
                         feature_fraction_seed=8,
                         min_sum_hessian_in_leaf = 11,
                         verbose=-1,
                         random_state=42)
# XGBoost Regressor
xgboost = XGBRegressor(learning_rate=0.01,n_estimators=1500, max_depth=4, min_child_weight=0,gamma=0.6, subsample=0.7,colsample_bytree=0.7,objective='reg:squarederror',nthread=-1,scale_pos_weight=1,seed=27,
                       reg_alpha=0.00006,
                       random_state=42)

xgboost2 = XGBRegressor(learning_rate=0.01, n_estimators=1500, max_depth=12,min_child_weight=0,gamma=0.6,subsample=0.7,colsample_bytree=0.7,objective='reg:squarederror',nthread=-1,scale_pos_weight=1,seed=27,
                       reg_alpha=0.00006,
                       random_state=42)
# Ridge Regressor
ridge_alphas = [1e-15, 1e-10, 1e-8, 9e-4, 7e-4, 5e-4, 3e-4, 1e-4, 1e-3, 5e-2, 1e-2, 0.1, 0.3, 1, 3, 5, 10, 15, 18, 20, 30, 50, 75, 100]
ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=ridge_alphas, cv=kf))

# Support Vector Regressor
svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003))

# Gradient Boosting Regressor
gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.01, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10,loss='huber', random_state=42)

gbr2 = GradientBoostingRegressor(n_estimators=1500, learning_rate=0.01, max_depth=1, max_features='sqrt',min_samples_leaf=15, min_samples_split=10, loss='huber', random_state=42)  

# Random Forest Regressor
rf = RandomForestRegressor(n_estimators=1200, max_depth=15, min_samples_split=5, min_samples_leaf=5, max_features=None, oob_score=True, random_state=42)

rf2 = RandomForestRegressor(n_estimators=1200, max_depth=5, min_samples_split=5, min_samples_leaf=5, max_features=None,oob_score=True, random_state=42)

# Stack up all the models above, optimized using xgboost
stack_gen = StackingCVRegressor(regressors=(xgboost, lightgbm, svr, ridge, gbr, gbr2,xgboost2), meta_regressor=xgboost,use_features_in_secondary=True)

"""# **MAE scores for several different maching learning algorithms**"""

# Title
scores = {}


score = cv_rmse(lightgbm)
print("lightgbm: {:.4f} ({:.4f})".format(score.mean(), score.std()))
scores['lgb'] = (score.mean(), score.std())

score = cv_rmse(xgboost)
print("xgboost: {:.4f} ({:.4f})".format(score.mean(), score.std()))
scores['xgb'] = (score.mean(), score.std())

score = cv_rmse(svr)
print("SVR: {:.4f} ({:.4f})".format(score.mean(), score.std()))
scores['svr'] = (score.mean(), score.std())

score = cv_rmse(ridge)
print("ridge: {:.4f} ({:.4f})".format(score.mean(), score. std()))
scores['ridge'] = (score.mean(), score.std())











#score = cv_rmse(rf)
#print("rf: {:.4f} ({:.4f})".format(score.mean(), score.std()))
#scores['rf'] = (score.mean(), score.std())

#score = cv_rmse(gbr)
#print("gbr: {:.4f} ({:.4f})".format(score.mean(), score.std()))
#scores['gbr'] = (score.mean(), score.std())

#score = cv_rmse(rf2)
#print("rf2: {:.4f} ({:.4f})".format(score.mean(), score.std()))
#scores['rf2'] = (score.mean(), score.std())

score = cv_rmse(xgboost2)
print("xgboost2: {:.4f} ({:.4f})".format(score.mean(), score.std()))
scores['xgboost2'] = (score.mean(), score.std())

score = cv_rmse(gbr2)
print("gbr2: {:.4f} ({:.4f})".format(score.mean(), score.std()))
scores['gbr2'] = (score.mean(), score.std())


stack_gen_model = stack_gen.fit(np.array(X2),np.array(Y2))
print('stack_gen')
print("gbr2: {:.4f} ({:.4f})".format(score.mean(), score.std()))

"""# Fitting the Model to the Testing Set"""

# Title
# Upload Training File
from google.colab import files
uploaded=files.upload()

"""# **Test Dataset**"""

#@title
import io
test=pd.read_csv(io.BytesIO(uploaded['Raw_Player_Values_Test.csv']))
test.head()
player_names=test.iloc[:,3]
z_test2=test.iloc[:,4:87]
z_test2.head()

"""# **Fitting the algorithms to the test dataset and blending their predictions to get a final prediction**"""

#@title
print('lightgbm')
lgb_model_full_data = lightgbm.fit(X2,Y2)

print('xgboost')
xgb_model_full_data = xgboost.fit(X2,Y2)

print('Svr')
svr_model_full_data = svr.fit(X2,Y2)

print('Ridge')
ridge_model_full_data = ridge.fit(X2,Y2)

#print('RandomForest')
#rf_model_full_data = rf.fit(X2,Y2)

print('GradientBoosting')
gbr_model_full_data = gbr.fit(X2,Y2)

print('GradientBoosting')
gbr2_model_full_data = gbr2.fit(X2,Y2)

#print('Random Forest 2')
#rf2_model_full_data = rf2.fit(X2,Y2)

print('xgboost2')
xgboost2_model_full_data = xgboost2.fit(X2,Y2)

def blended_predictions(z_test2):
    return ((0.0 * ridge_model_full_data.predict(z_test2) + \
            (0* gbr2_model_full_data.predict(z_test2)) + \
            (1* xgboost2_model_full_data.predict(z_test2)) + \
            (0* gbr_model_full_data.predict(z_test2)) + \
            (0* xgb_model_full_data.predict(z_test2)) + \
            (0* lgb_model_full_data.predict(z_test2)) + \
            (0 * stack_gen_model.predict(np.array(z_test2)))))

"""Predicted cap hit% for the 2019-2020 skater class. The term predicted by the term model was used as the model input for the cap hit% model."""

#@title

predictions = pd.DataFrame(blended_predictions(z_test2))
predictions = pd.concat([player_names, predictions], axis=1)

predictions

from google.colab import files

predictions.to_csv('Raw_Player_Projections.csv')
files.download('Raw_Player_Projections.csv')

"""# Visualizing Feature Importance"""

#@title
# Install SHAP
!pip install shap==0.27
import shap

#@title
#Vizuallise feature importances with Shap (global)
explainer = shap.TreeExplainer(lightgbm)
shap_values = explainer.shap_values(X2)

"""The following graph shows the 20 most important features in the cap hit% model. 

The graph has a lot of moving parts so we'll take a look at one variable and detail what the graph is representing.

Lets take TOI% as an example, the colour scale of the graph, represented by the legend on the right, indicates that high feature values (in this case high TOI%) are coloured red and low feature values (low TOI%) are coloured as blue. 

The **density** of the feature is represented by the thickness of the line - for TOI%  the left side of the line has two thick spots colored blue and pinkish blue which mean a large number of players have low TOI%. The thinner red part of the line towards the right shows there are high values for TOI% but few players have these values. 

The scale at the bottom of the graph 'SHAP Value (impact on model output)' represents the effect the variable has on the model ouput. Negative SHAP values (values left of the vertical line through the centre of the graph) have a negative effect on the model output and positive SHAP values (values right of the vertical line) have a positive impact on the model output. For TOI%, low feature values (represented by blue) have a negative effect on the model out put and high TOI% (represented by red) have a large postive effect on the model output. 

Essentially for TOI% the graph is telling us that most players have low TOI% values, thus lowering their cap hit% values and a select number of players have high TOI% which has a dramatic increase on their cap hit % values. 


This same sort of trend is evident for A1, iCF, G, CF%_QOT, CF%_QOC - low feature values result in low model outputs and high feature values result in high model outputs. 

The plot also confirms our intuition for variables NCL1 and NCL2 - if a player signs a 1 or 2 year deal their resultant cap hit% is lower. For NCL1 and NCL2 'high' feature values simply means a player has a 1 for that category and low feature values means a player has a zero for that category. This explains the colour scale as dark red and dark blue as their are only two possible values the variable can have.
"""

#@title
#Plot
plt.figure(figsize=(7,6))
shap.summary_plot(shap_values,X2)
plt.tight_layout()
plt.show()

"""The following table enumerates what the graph above is showing. It captures the overall feature importance for each variable in a single number. 

We'll go through the 10 most important features the model found, and why we feel the model considered them so heavily,

**1. TOI%**

Players who play a lot get paid occordingly. 

**2. OCH%**

Is very telling of future cap hit% especially for contracts that were signed after a players original contract was very high. 

**3. NCL1**

If a contract is not one year in length the resulant cap hit% is generally higher

**4. NCL2**

Like NCL1, if a contract is not two years in length the resultant cap hit% is generally higher.

**5. A1**

Players with more primary points have higher cap hit%.

**6. iCF**

Players with mroe individual shot attempts generally produce more offense

**7. CF%_QOT**

Players who play with good linemates make more money. Higher quality teammates also result in higher box stats. 

**8. G**

Similiar to A1 - players with more primary points have higher cap hit%.

**9. CF%_QOC**

Similiar to QOT (generally), if you are tasked with playing against other teams top lines you are probably in your own teams top6/top4. 


**10. OCL**

Interestingly, longer previous contracts result in higher cap hit% on a players future contract. A good example would be players who sign 5-8 years deals as RFA's - their UFA contracts usually have high cap hit% if they were good enough to recieve a long term deal after their ELC.
"""

#@title
shap_sum = np.abs(shap_values).mean(axis=0)
importance_df = pd.DataFrame([X2.columns.tolist(), shap_sum.tolist()]).T
importance_df.columns = ['column_name', 'shap_importance']
importance_df = importance_df.sort_values('shap_importance', ascending=False)
importance_df

"""# SHAP Dependance Plots

The following plots are essentially scatter plots of the first graph presented. The plots show each variables influence on the model output.  The x-axis of the plot is the variable value and the y-axis is the SHAP values which measures the variables relative influence on the model output. For the categorical variables (AGE1, AGE2, AGE3, AGE4, AGE5, NSS, OCS_RFA, OCS_UFA, ARBITRATION, NCL1, NCL2, NCL3, NCL4, NCL5, NCL6, NCL7) the input variable takes on only two values - 0 and 1. If a player falls within the specified category they have a 1 and if not they have a 0.

The remaining variables are continuous and most plots show a general increase in model output with an increase in variable values. One interesting plot was iSh% which values peak between 12-15% and then trails off for higher values. This is probably because shooting percentages between 12-15% are on the high end of true shooting talent with 16-25% being more luck than talent.

The plot for SHTOI% follows an interesting U shape where both low and high values for SHTOI% have a large positive impact on model output.

The plots for iBLK, iPEND2 and iPENT2 are mostly random.
"""

#@title
for name in X2.columns:
    shap.dependence_plot(name, shap_values, X2, interaction_index= None)

"""# **The following graphics capture what individual features are driving the model scores for indivdual players. We have presented select UFA/RFA players from the blue jackets.**

# Artemi Panarin - 8 years X $10,524,940

Panarin is an elite player with the highest model output of any player in our test set. His goals, primary assists, TOI%, iCF, CF%_QOT all contribute to his high model score. According the model the factors negatively effecting his model output are his raw TOI value and the fact his last contract was two years in length.
"""

#@title
#visualize the test set predictions
shap.initjs()
test_sample = z_test2
shap_values_sample = explainer.shap_values(test_sample)
shap.force_plot(explainer.expected_value, shap_values_sample[7,:], test_sample.iloc[7,:], link="logit")

"""# Zach Werenski - 6 years X $6,886,498

Werenski is an elite defender deserving of a long term deal. His offensive production and TOI% are the driving factors of his model score. His low OCH% (which essentially means he is an RFA not a UFA) and weaker quality of competition are keeping his cap hit % from reaching double digits.
"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[43,:], test_sample.iloc[43,:], link="logit")

"""# Matt Duchene - 5 years X $5,732,475

**The model was low on Matt Duchene because of his low A1 and TOI%. (These values seem off and their may have been an issue with the data collection.)**
"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[86,:], test_sample.iloc[86,:], link="logit")

"""# Ryan Murray - 1 year X $4,049,188

**Ryan Murray's TOI% pushed his model score, but the fact his contract is predicted to be 1 year is lowering his model output.**
"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[225,:], test_sample.iloc[225,:], link="logit")

"""# Ryan Dzingel - 3 years X $3,615,317"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[35,:], test_sample.iloc[35,:], link="logit")

"""# Adam Mcquaid 2 years X $2,509,252"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[203,:], test_sample.iloc[203,:], link="logit")

"""# Scott Harrington - 3 years X 2,063,482"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[193,:], test_sample.iloc[193,:], link="logit")

"""# Lukas Sedlak - 3 years X 1,791,393"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[131,:], test_sample.iloc[131,:], link="logit")

"""# Markus Hannikainen 3 years X 1,781,573"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[139,:], test_sample.iloc[139,:], link="logit")

"""# Sonny Milano - 2 years X 1,750,610"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[83,:], test_sample.iloc[83,:], link="logit")

"""# **Eric Robinson** 2 years X 1,345,248"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[253,:], test_sample.iloc[253,:], link="logit")

"""# Conclusion - Cap Percentage Model

In hindsight, basing the model off of previous work may have limited the quality of our results. The assumptions made by Matt Cane and evolving wild may not be appropriate in what we tried to do with the model and some of the additional metrics we included resulted in some unrealistic results. For exampe, Eric Robinson is projected to have a cap hit of around 1.3 million which is no where near what he will (and should) make. QOT/QOC metrics made a lot of the projections for fringe players unrealistic - the model found these metrics so important that if a player had little TOI and production but decent teammates and competition they would recieve well over $1 million.

# Final Thoughts and Future Work

The model needs some fine-tuning before it can be reliably trusted, but the initial results and insights are promising. We would like to revisit how a players previous seasons are weighted, try out more input variables and find a way to capture market effects as an input variable.

# Kasperi Kapanen 3 years X 2,666,925
"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[45,:], test_sample.iloc[45,:], link="logit")

"""# Andreas Johnsson 2 years X $2,651,526"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[17,:], test_sample.iloc[17,:], link="logit")

"""# Brayden Point 6 years X $6,465,341"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[2,:], test_sample.iloc[2,:], link="logit")

"""# Kevin Hayes 8 years X $8,176,750"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[33,:], test_sample.iloc[33,:], link="logit")

"""# Brandon Pirri 2 years X $1,780,710"""

#@title
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values_sample[48,:], test_sample.iloc[48,:], link="logit")